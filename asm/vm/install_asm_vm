#!/usr/bin/env bash
set -CeE
set -o pipefail
if [[ "${BASH_VERSINFO:-0}" -lt 4 ]]; then
  cat << EOF >&2
WARNING: bash ${BASH_VERSION} does not support several modern safety features.
This script was written with the latest POSIX standard in mind, and was only
tested with modern shell standards. This script may not perform correctly in
this environment.
EOF
  sleep 1
else
  set -u
fi

### Internal variables ###
MAJOR="${MAJOR:=1}"
MINOR="${MINOR:=8}"
POINT="${POINT:=1}"
ASM_RELEASE="${MAJOR}.${MINOR}"
ASM_META_VERSION="${MAJOR}.${MINOR}.${POINT}"
readonly ASM_RELEASE
readonly ASM_META_VERSION

SCRIPT_NAME="${0##*/}"

PROJECT_NUMBER=""

DNS_IP=""
ROOT_CERT=""
INGRESS_IP=""
MESH_AGENT_BUCKET=\
"gs://gce-mesh/service-proxy-agent/releases/service-proxy-agent-0.2-asm.tgz"
INSTANCE_IPS=""
CANONICAL_SERVICE=""
CANONICAL_REVISION=""

IP_REGEX="^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$"

### Command internal toggle ###
CREATE_GCE_INSTANCE_TEMPLATE=0

### Option variables ###
PROJECT_ID="${PROJECT_ID:=}"
CLUSTER_NAME="${CLUSTER_NAME:=}"
CLUSTER_LOCATION="${CLUSTER_LOCATION:=}"
SOURCE_INSTANCE_TEMPLATE="${SOURCE_INSTANCE_TEMPLATE:=}"
WORKLOAD_NAME="${WORKLOAD_NAME:=}"
WORKLOAD_LABELS="${WORKLOAD_LABELS:=}"
WORKLOAD_SERVICE_ACCOUNT="${WORKLOAD_SERVICE_ACCOUNT:=}"

NEW_INSTANCE_TEMPLATE=""

SERVICE_ACCOUNT="${SERVICE_ACCOUNT:=}"
KEY_FILE="${KEY_FILE:=}"

DRY_RUN="${DRY_RUN:=0}"
ONLY_VALIDATE="${ONLY_VALIDATE:=0}"
VERBOSE="${VERBOSE:=0}"

### Convenience functions ###

#######
# run takes a list of arguments that represents a command
# If DRY_RUN or VERBOSE is enabled, it will print the command, and if DRY_RUN is
# not enabled it runs the command.
#######
run() {
  if [[ "${DRY_RUN}" -eq 1 ]]; then
    warn "Would have executed: ${*}"
    return
  elif [[ "${VERBOSE}" -eq 0 ]]; then
    "${@}" 2>/dev/null
    return "$?"
  fi
  info "Running: '${*}'"
  info "-------------"
  local RETVAL
  { "${@}"; RETVAL="$?"; } || true
  return $RETVAL
}

#######
# retry takes an integer N as the first argument, and a list of arguments
# representing a command afterwards. It will retry the given command up to N
# times before returning 1. If the command is kubectl, it will try to
# re-get credentials in case something caused the k8s IP to change.
#######
retry() {
  local MAX_TRIES; MAX_TRIES="${1}";
  shift 1
  for i in $(seq 0 "${MAX_TRIES}"); do
    if [[ "${i}" -eq "${MAX_TRIES}" ]]; then
      false
    fi
    { "${@}" && return 0; } || true
    warn "Failed, retrying...($((i+1)) of ${MAX_TRIES})"
    sleep 2
    if [[ "$1" == "kubectl" ]]; then
      configure_kubectl
    fi
  done
  false
}

#######
# watch_for_result takes an integer N as the first argument, a regex pattern as
# the second argument (use `.*` for any value), and a list of arguments
# representing a command afterwards. It will retry the given command up to N
# seconds for output. If the output does not match the regex pattern before
# timeout, it returns 1.
######
watch_for_result() {
  local TIMEOUT; TIMEOUT="${1}";
  local PATTERN; PATTERN="${2}";
  shift 2
  if [[ "${DRY_RUN}" -ne 0 ]]; then
    warn "Would have executed: ${*}"
    return
  fi
  local VALUE; VALUE="";
  for i in $(seq 0 "${TIMEOUT}"); do
    if [[ "${i}" -eq "${TIMEOUT}" ]]; then
      warn "Timed out when waiting for the output of: ${*}"
      break
    fi
    VALUE=$("${@}") || true
    { [[ -n "${VALUE}" && "${VALUE}" =~ $PATTERN ]] \
      && echo "${VALUE}" && return 0; } || true
    sleep 1
  done
  return 1
}

strip_last_char() {
  echo "${1:0:$((${#1} - 1))}"
}

configure_kubectl(){
  info "Fetching/writing GCP credentials to kubeconfig file..."
  retry 2 run gcloud container clusters get-credentials "${CLUSTER_NAME}" \
    --project="${PROJECT_ID}" \
    --zone="${CLUSTER_LOCATION}"

  info "Verifying connectivity (20s)..."
  local RETVAL; RETVAL=0;
  kubectl cluster-info --request-timeout='20s' 1>/dev/null 2>/dev/null || RETVAL=$?
  if [[ "${RETVAL}" -ne 0 ]]; then
    { read -r -d '' MSG; fatal "${MSG}"; } <<EOF || true
Couldn't connect to ${CLUSTER_NAME}.
If this is a private cluster, verify that the correct firewall rules are applied.
https://cloud.google.com/service-mesh/docs/gke-install-overview#requirements
EOF
  fi
  info "kubeconfig set to ${PROJECT_ID}/${CLUSTER_LOCATION}/${CLUSTER_NAME}..."
}

warn() {
  info "[WARNING]: ${1}" >&2
}

error() {
  info "[ERROR]: ${1}" >&2
}

info() {
  echo "${SCRIPT_NAME}: ${1}" >&2
}

fatal() {
  error "${1}"
  exit 2
}

fatal_with_usage() {
  warn "${1}"
  if [[ "${CREATE_GCE_INSTANCE_TEMPLATE}" -eq 1 ]]; then
    usage_create_gce_instance_template >&2
  else
    usage_asm_vm >&2
  fi
  exit 2
}

usage_asm_vm() {
  cat << EOF
usage: ${SCRIPT_NAME} <COMMAND>

ASM VM command line utility to add GCE instances to Anthos Service Mesh.

COMMANDS:
  create_gce_instance_template   Create a new GCE instance template for ASM VMs.

OPTIONS:
  -h|--help                      Show this message and exit.

Use "${SCRIPT_NAME} <COMMAND> --help" for more information about a command.
EOF
}

usage_create_gce_instance_template() {
  cat << EOF
usage: ${SCRIPT_NAME} create_gce_instance_template NAME [OPTION]...

Prepare a GCE VM template used for VMs to be added to an existing ASM cluster.
All options can also be passed via environment variables by using the ALL_CAPS
name. Options specified via flags take precedence over environment variables.

POSITIONAL ARGUMENTS:
  NAME                                              Name of the instance
                                                    template to create.

OPTIONS:
  -l|--cluster_location         <LOCATION>          The GCP location of the
                                                    target cluster.
  -n|--cluster_name             <NAME>              The name of the target
                                                    cluster.
  -p|--project_id               <ID>                The GCP project ID.
  -w|--workload_name            <WORKLOAD_NAME>     The name of the workload
                                                    running on the GCE
                                                    instance(s).
  -e|--workload_labels          <WORKLOAD_LABELS>   (optional) The
                                                    labels of the workload,
                                                    comma separated.
  -i|--source_instance_template <TEMPLATE>          (optional) The name of the
                                                    source GCE instance
                                                    template.
  -s|--service_account          <SERVICE_ACCOUNT>   (optional) The name of a
                                                    service account used to run
                                                    the script.
  -k|--key_file                 <FILE PATH>         (optional) The key file for
                                                    a service account. Required
                                                    if --service_account is
                                                    passed.

FLAGS:

  -v|--verbose                                      Print commands before and
                                                    after execution.
     --dry_run                                      Print commands, but don't
                                                    execute them.
     --only_validate                                Run validation but don't
                                                    install.
  -h|--help                                         Show this message and exit.

EXAMPLE:
The following invocation will prepare a GCE VM template named "my_vm_template"
in project "my_project" based on the configurations in ASM cluster "my_cluster"
in zone "us-central1-c":
  $> ${SCRIPT_NAME} create_gce_instance_template my_vm_template \\
      -n my_cluster \\
      -p my_project \\
      -l us-central1-c \\
      -i base_vm_template \\
      -w checkout \\
      -e app=checkout
EOF
}

arg_required() {
  if [[ ! "${2:-}" || "${2:0:1}" = '-' ]]; then
    fatal "Option ${1} requires an argument."
  fi
}

parse_args() {
  # shellcheck disable=SC2064
  trap "$(shopt -p nocasematch)" RETURN
  shopt -s nocasematch

  if [[ ! "${1:-}" ]]; then
    fatal_with_usage "${SCRIPT_NAME} requires a command."
  fi

  case "${1}" in
    create_gce_instance_template)
      CREATE_GCE_INSTANCE_TEMPLATE=1; readonly CREATE_GCE_INSTANCE_TEMPLATE;
      parse_args_create_gce_instance_template "${@}"
      shift 1
      ;;
    -h | --help)
      usage_asm_vm
      exit
      ;;
    *)
      fatal_with_usage "Unknown command ${1}"
      ;;
  esac
}

parse_args_create_gce_instance_template() {
  # shellcheck disable=SC2064
  trap "$(shopt -p nocasematch)" RETURN
  shopt -s nocasematch

  if [[ ! "${2:-}" || "${2:0:1}" = '-' ]]; then
    fatal_with_usage "Command create_gce_instance_template requires an argument."
  fi
  NEW_INSTANCE_TEMPLATE="${2}"
  shift 2

  while [[ ${#} != 0 ]]; do
    case "${1}" in
      -l | --cluster_location | --cluster-location)
        arg_required "${@}"
        CLUSTER_LOCATION="${2}"
        shift 2
        ;;
      -n | --cluster_name | --cluster-name)
        arg_required "${@}"
        CLUSTER_NAME="${2}"
        shift 2
        ;;
      -p | --project_id | --project-id)
        arg_required "${@}"
        PROJECT_ID="${2}"
        shift 2
        ;;
      -i | --source_instance_template | --source-instance-template)
        arg_required "${@}"
        SOURCE_INSTANCE_TEMPLATE="${2}"
        shift 2
        ;;
      -w | --workload_name | --workload-name)
        arg_required "${@}"
        WORKLOAD_NAME="${2}"
        shift 2
        ;;
      -e | --workload_labels | --workload-labels)
        arg_required "${@}"
        WORKLOAD_LABELS="${2}"
        shift 2
        ;;
      -s | --service_account | --service-account)
        arg_required "${@}"
        SERVICE_ACCOUNT="${2}"
        shift 2
        ;;
      -k | --key_file | --key-file)
        arg_required "${@}"
        KEY_FILE="${2}"
        shift 2
        ;;
      --dry_run | --dry-run)
        DRY_RUN=1
        shift 1
        ;;
      --only_validate | --only-validate)
        ONLY_VALIDATE=1
        shift 1
        ;;
      -v | --verbose)
        VERBOSE=1
        shift 1
        ;;
      -h | --help)
        usage
        exit
        ;;
      *)
        fatal_with_usage "Unknown option ${1}"
        ;;
    esac
  done
}

validate_args() {
  local MISSING_ARGS; MISSING_ARGS=0
  while read -r REQUIRED_ARG; do
    if [[ -z "${!REQUIRED_ARG}" ]]; then
      MISSING_ARGS=1
      warn "Missing value for ${REQUIRED_ARG}"
    fi
    readonly "${REQUIRED_ARG}"
  done <<EOF
CLUSTER_LOCATION
CLUSTER_NAME
PROJECT_ID
WORKLOAD_NAME
EOF

  if [[ "${MISSING_ARGS}" -ne 0 ]]; then
    fatal_with_usage "Missing one or more required options."
  fi

  while read -r FLAG; do
    if [[ "${!FLAG}" -ne 0 && "${!FLAG}" -ne 1 ]]; then
      fatal "${FLAG} must be 0 (off) or 1 (on) if set via environment variables."
    fi
    readonly "${FLAG}"
  done <<EOF
DRY_RUN
ONLY_VALIDATE
VERBOSE
EOF

  local LABEL_PAT
  LABEL_PAT="^([^=,[:space:]]+)=([^=,[:space:]]+)(,([^=,[:space:]]+)=([^=,[:space:]]+))*$"
  if [[ -n "${WORKLOAD_LABELS}" && ! "${WORKLOAD_LABELS}" =~ $LABEL_PAT ]]; then
    fatal "Workload labels ${WORKLOAD_LABELS} are not specified in the correct format. Example: app=label,env=prod"
  fi

  if [[ -n "$SERVICE_ACCOUNT" && -z "$KEY_FILE" || -z "$SERVICE_ACCOUNT" && -n "$KEY_FILE" ]]; then
    fatal "Service account and key file must be used together."
  fi

  # since we cd to a tmp directory, we need the absolute path for the key file
  # and yaml file
  if [[ -f "${KEY_FILE}" ]]; then
    KEY_FILE="$(apath -f "${KEY_FILE}")"
    readonly KEY_FILE
  elif [[ -n "${KEY_FILE}" ]]; then
    fatal "Couldn't find key file ${KEY_FILE}."
  fi
}

auth_service_account() {
  info "Authorizing ${SERVICE_ACCOUNT} with ${KEY_FILE}..."
  run gcloud auth activate-service-account \
    --project="${PROJECT_ID}" \
    "${SERVICE_ACCOUNT}" \
    --key-file="${KEY_FILE}"
}

### Environment validation functions ###
validate_dependencies() {
  validate_cli_dependencies
  validate_project
  PROJECT_NUMBER="$(gcloud projects describe "${PROJECT_ID}" \
    --format="value(projectNumber)")"
  validate_asm_cluster

  if [[ "${CREATE_GCE_INSTANCE_TEMPLATE}" -eq 1 ]]; then
    validate_gce_instance_template
  fi
}

validate_cli_dependencies() {
  local NOTFOUND; NOTFOUND="";
  local EXITCODE; EXITCODE=0;

  info "Checking installation tool dependencies..."
  while read -r dependency; do
    EXITCODE=0
    hash "${dependency}" 2>/dev/null || EXITCODE=$?
    if [[ "${EXITCODE}" -ne 0 ]]; then
      NOTFOUND="${dependency},${NOTFOUND}"
    fi
  done <<EOF
gcloud
curl
jq
tr
awk
xargs
printf
kubectl
EOF

  if [[ -n "${NOTFOUND}" ]]; then
    NOTFOUND="$(strip_last_char "${NOTFOUND}")"
    for dep in $(echo "${NOTFOUND}" | tr ' ' '\n'); do
      warn "Dependency not found: ${dep}"
    done
    fatal "One or more dependencies were not found. Please install them and retry."
  fi

  local OS
  # shellcheck disable=SC2064
  trap "$(shopt -p nocasematch)" RETURN
  shopt -s nocasematch
  if [[ "$(uname -m)" != "x86_64" ]]; then
    fatal "Installation is only supported on x86_64."
  fi
}

validate_project() {
  local RESULT; RESULT=""

  info "Checking for ${PROJECT_ID}..."
  RESULT=$(gcloud projects list \
    --filter="project_id=${PROJECT_ID}" \
    --format="value(project_id)" \
    || true)

  if [[ -z "${RESULT}" ]]; then
    { read -r -d '' MSG; fatal "${MSG}"; } <<EOF
Unable to find project ${PROJECT_ID}. Please verify the spelling and try
again. To see a list of your projects, run:
  gcloud projects list --format='value(project_id)'
EOF
  fi
}

validate_asm_cluster() {
  validate_cluster
  configure_kubectl
  validate_asm_installation
  validate_project_namespace
  validate_retrieve_istio_dns
}

validate_cluster() {
  local RESULT; RESULT=""

  info "Confirming cluster information for ${PROJECT_ID}/${CLUSTER_LOCATION}/${CLUSTER_NAME}..."
  RESULT="$(gcloud container clusters list \
    --project="${PROJECT_ID}" \
    --filter="name = ${CLUSTER_NAME} and location = ${CLUSTER_LOCATION}" \
    --format="value(name)" || true)"
  if [[ -z "${RESULT}" ]]; then
    { read -r -d '' MSG; fatal "${MSG}"; } <<EOF || true
Unable to find cluster ${CLUSTER_LOCATION}/${CLUSTER_NAME}.
Please verify the spelling and try again. To see a list of your clusters, in
this project, run:
  gcloud container clusters list --format='value(name,zone)' --project="${PROJECT_ID}"
EOF
  fi
}

validate_asm_installation() {
  info "Checking for istio-system namespace..."
  if [ "$(retry 2 kubectl get ns | grep -c istio-system || true)" -eq 0 ]; then
    fatal "istio-system namespace cannot be found in the cluster. Please install ASM and retry."
  fi

  info "Verifying ASM installation..."
  local ASM_DEPLOYMENT; ASM_DEPLOYMENT="istiod,istio-ingressgateway"
  for deploy in $(echo "${ASM_DEPLOYMENT}" | tr ',' '\n'); do
    local DEPLOY_NAME
    DEPLOY_NAME="$(retry 2 kubectl get deployment -n istio-system | \
      grep "${deploy}" | awk '{print $1}' || true)"
    if [ -z "${DEPLOY_NAME}" ]; then
      fatal "${deploy} cannot be found in the cluster. Please re-install ASM and retry."
    fi
    if ! [[ "$(retry 2 kubectl get deployment "${DEPLOY_NAME}" \
      -n istio-system \
      -o=jsonpath="{.spec.template.spec.containers[0].image}")" \
      =~ $ASM_RELEASE ]]; then
      fatal "${deploy} is not in ASM version ${ASM_RELEASE}. Please install ASM ${ASM_RELEASE} and retry."
    fi
  done
}

validate_project_namespace() {
  info "Checking for ${PROJECT_ID} namespace..."
  if [ "$(retry 2 kubectl get ns | grep -c "${PROJECT_ID}" || true)" -eq 0 ]; then
    fatal \
"${PROJECT_ID} namespace cannot be found in the cluster. Please create the
namespace. For example:
  kubectl create ns ${PROJECT_ID}"
  fi
}

validate_retrieve_istio_dns() {
  local RESULT; RESULT=""

  RESULT="$(kubectl get service istio-dns -n kube-system || true)"
  if [[ -z "${RESULT}" ]]; then
    fatal "istio-dns service not found on the cluster. Please follow the user
guide and create a DNS service for VMs."
  fi

  if [[ "${CREATE_GCE_INSTANCE_TEMPLATE}" -eq 0 ]]; then
    return 0
  fi

  # Only looking for an IP format matching from the kubernetes field that
  # includes the DNS IP address.
  info "Retrieving the Istio DNS service IP address..."
  local RETVAL
  { DNS_IP=$(watch_for_result 15 "${IP_REGEX}" kubectl get service \
  istio-dns -n kube-system \
  -o jsonpath='{.status.loadBalancer.ingress[0].ip}'); RETVAL="$?"; } || true
  if [[ "${RETVAL}" -ne 0 ]]; then
    fatal "Failed to retrieve the Istio DNS IP address."
  fi
}

validate_gce_instance_template() {
  local RESULT; RESULT=""

  info "Confirming GCE instance template information..."

  if [[ -n "${NEW_INSTANCE_TEMPLATE}" ]]; then
    RESULT="$(gcloud compute instance-templates list \
      --project="${PROJECT_ID}" \
      --filter="name~^${NEW_INSTANCE_TEMPLATE}$" \
      --format="value(name)" || true)"
    if [[ -n "${RESULT}" ]]; then
      { read -r -d '' MSG; fatal "${MSG}"; } <<EOF || true
GCE instance template ${NEW_INSTANCE_TEMPLATE} already exists.
Please choose a different name and try again. To see a list of your instance templates in
this project, run:
  gcloud compute instance-templates list \
  --format='value(name)' \
  --project="${PROJECT_ID}"
EOF
    fi
  fi

  if [[ -n "${SOURCE_INSTANCE_TEMPLATE}" ]]; then
    RESULT="$(gcloud compute instance-templates list \
      --project="${PROJECT_ID}" \
      --filter="name~^${SOURCE_INSTANCE_TEMPLATE}$" \
      --format="value(name)" || true)"
    if [[ -z "${RESULT}" ]]; then
      { read -r -d '' MSG; fatal "${MSG}"; } <<EOF || true
Unable to find GCE instance template ${SOURCE_INSTANCE_TEMPLATE}.
Please verify the spelling and try again. To see a list of your instance templates in
this project, run:
  gcloud compute instance-templates list \
  --format='value(name)' \
  --project="${PROJECT_ID}"
EOF
    fi
  fi
}

extract_canonical_service_label() {
  local SERVICE_ISTIO_IO_CANONICAL_NAME; SERVICE_ISTIO_IO_CANONICAL_NAME=""
  local APP_KUBERNETES_IO_NAME; APP_KUBERNETES_IO_NAME=""
  local APP; APP=""
  for label in $(echo "${WORKLOAD_LABELS}" | tr ',' '\n'); do
    IFS='=' read -r -a pair <<< "${label}"
    if [[ "${pair[0]}" == "service.istio.io/canonical-name" ]]; then
      SERVICE_ISTIO_IO_CANONICAL_NAME="${pair[1]}"
    fi
    if [[ "${pair[0]}" == "app.kubernetes.io/name" ]]; then
      APP_KUBERNETES_IO_NAME="${pair[1]}"
    fi
    if [[ "${pair[0]}" == "app" ]]; then
      APP="${pair[1]}"
    fi
  done

  if [[ -n "${SERVICE_ISTIO_IO_CANONICAL_NAME}" ]]; then
    CANONICAL_SERVICE="${SERVICE_ISTIO_IO_CANONICAL_NAME}"
  elif [[ -n "${APP_KUBERNETES_IO_NAME}" ]]; then
    CANONICAL_SERVICE="${APP_KUBERNETES_IO_NAME}"
  elif [[ -n "${APP}" ]]; then
    CANONICAL_SERVICE="${APP}"
  else
    CANONICAL_SERVICE="${WORKLOAD_NAME}"
  fi
}

extract_canonical_service_revision() {
  local SERVICE_ISTIO_IO_CANONICAL_REVISION; SERVICE_ISTIO_IO_CANONICAL_REVISION=""
  local APP_KUBERNETES_IO_VERSION; APP_KUBERNETES_IO_VERSION=""
  local VERSION; VERSION=""
  for label in $(echo "${WORKLOAD_LABELS}" | tr ',' '\n'); do
    IFS='=' read -r -a pair <<< "${label}"
    if [[ "${pair[0]}" == "service.istio.io/canonical-revision" ]]; then
      SERVICE_ISTIO_IO_CANONICAL_REVISION="${pair[1]}"
    fi
    if [[ "${pair[0]}" == "app.kubernetes.io/version" ]]; then
      APP_KUBERNETES_IO_VERSION="${pair[1]}"
    fi
    if [[ "${pair[0]}" == "version" ]]; then
      VERSION="${pair[1]}"
    fi
  done

  if [[ -n "${SERVICE_ISTIO_IO_CANONICAL_REVISION}" ]]; then
    CANONICAL_REVISION="${SERVICE_ISTIO_IO_CANONICAL_REVISION}"
  elif [[ -n "${APP_KUBERNETES_IO_VERSION}" ]]; then
    CANONICAL_REVISION="${APP_KUBERNETES_IO_VERSION}"
  elif [[ -n "${VERSION}" ]]; then
    CANONICAL_REVISION="${VERSION}"
  else
    CANONICAL_REVISION="latest"
  fi
}

retrieve_cluster_root_cert() {
  info "Retrieving the cluster's root certificate..."

  local ISTIOD; ISTIOD=""
  ISTIOD=$(kubectl get pods -oname -lapp=istiod -n istio-system | head -n 1 || true)
  ROOT_CERT=$(kubectl exec -it -n istio-system "${ISTIOD}" \
    -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt \
    | awk 'NF {sub(/\r/, ""); printf "%s\n",$0;}' || true)
  if [[ -z "${ROOT_CERT}" ]]; then
    fatal "Error retrieving the cluster's root certificate from Istiod pod ${ISTIOD}. Please try again."
  fi
}

retrieve_ingressgateway() {
  info "Retrieving the cluster's Istio ingress gateway IP..."

  local RETVAL
  { INGRESS_IP=$(watch_for_result 15 "${IP_REGEX}" kubectl get service \
    istio-ingressgateway -n istio-system \
    -o jsonpath='{.status.loadBalancer.ingress[0].ip}'); RETVAL="$?"; } || true
  if [[ "${RETVAL}" -ne 0 ]]; then
    fatal "Failed to retrieve the Istio ingress gateway IP address."
  fi
}

# Generate GCE service proxy definition for the instance template
gen_gce_service_proxy() {
  local PROXY
  PROXY=$(jq -n --arg ingress_ip "${INGRESS_IP}" \
    --arg project_id "${PROJECT_ID}" \
    --arg workload_name "${WORKLOAD_NAME}" \
    --arg canonical_service "${CANONICAL_SERVICE}" \
    --arg canonical_revision "${CANONICAL_REVISION}" \
    --arg project_number "${PROJECT_NUMBER}" \
    --arg asm_meta_version "${ASM_META_VERSION}" '{
  "mode": "ON",
  "proxy-spec": {
    "access-log": "/var/log/envoy/access.log",
    "network": "default",
    "tracing": "ON",
    "api-server" : ($ingress_ip+":15012"),
    "log-level": "debug"
  },
  "labels": {
    "workload-pool": ($project_id+".svc.id.goog")
  },
  "asm-labels": {
    "service.istio.io/canonical-name": $canonical_service,
    "service.istio.io/canonical-revision": $canonical_revision
  },
  "asm-env": {
    "ISTIO_META_WORKLOAD_NAME": $workload_name,
    "ISTIO_META_MESH_ID": ("proj-"+$project_number),
    "ISTIO_META_ISTIO_VERSION": $asm_meta_version,
    "POD_NAMESPACE": $project_id,
    "CANONICAL_SERVICE": $canonical_service,
    "CANONICAL_REVISION": $canonical_revision,
    "USE_TOKEN_FOR_CSR": "true"
  },
  "service": {}
}')

  # Append each workload label pair into asm_labels field of GCE_SERVICE_PROXY
  # as a valid JSON object.
  for label in $(echo "${WORKLOAD_LABELS}" | tr ',' '\n'); do
    IFS='=' read -r -a pair <<< "${label}"
    PROXY=$(jq --arg key "${pair[0]}" \
    --arg value "${pair[1]}" \
    '."asm-labels"[$key]=$value' <<< "${PROXY}")
  done

  echo "${PROXY}"
}

# Define the GCE software declaration for OS config.
gce_software_declaration() {
  jq -n '{
  "softwareRecipes": [{
      "name": "install-gce-service-proxy-agent",
      "desired_state": "INSTALLED",
      "installSteps": [{
          "scriptRun": {
            "script": "#!/bin/bash\nSERVICE_PROXY_AGENT_BUCKET=$(curl \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/service-proxy-agent-bucket\" -H \"Metadata-Flavor: Google\")\nARCHIVE_NAME=$(basename ${SERVICE_PROXY_AGENT_BUCKET})\nexport SERVICE_PROXY_AGENT_DIRECTORY=$(mktemp -d)\nsudo gsutil cp ${SERVICE_PROXY_AGENT_BUCKET} ${SERVICE_PROXY_AGENT_DIRECTORY}\nsudo tar -xzf ${SERVICE_PROXY_AGENT_DIRECTORY}/${ARCHIVE_NAME} -C ${SERVICE_PROXY_AGENT_DIRECTORY}\n${SERVICE_PROXY_AGENT_DIRECTORY}/service-proxy-agent/service-proxy-agent-bootstrap.sh"
          }
        }
      ]
    }
  ]
}'
}

# Generate startup script for the instance template.
gen_startup_script() {
  local EXISTING_STARTUP_SCRIPT; EXISTING_STARTUP_SCRIPT="${1}";
  ISTIOD_ENTRY="${INGRESS_IP} istiod.istio-system.svc"; readonly ISTIOD_ENTRY;
  SCRIPT='# Scripts below are added by Google Cloud Anthos Service Mesh for VM Installation.
if ! grep -Fq "'"${ISTIOD_ENTRY}"'" /etc/hosts; then
  echo "'"${ISTIOD_ENTRY}"' # Added by Google Cloud for Anthos Service Mesh for VM Installation" | sudo tee -a /etc/hosts
fi
sudo apt-get install resolvconf -y
echo "nameserver '"${DNS_IP}"' # Added by Google Cloud for Anthos Service Mesh for VM Installation" | sudo tee -a /etc/resolvconf/resolv.conf.d/head
sudo systemctl restart resolvconf'
  readonly SCRIPT

  if [[ -n "${EXISTING_STARTUP_SCRIPT}" ]]; then
    echo -e "${EXISTING_STARTUP_SCRIPT}\n${SCRIPT}"
  else
    echo -e "#!/bin/bash\n${SCRIPT}"
  fi
}

# Generate metadata for the instance tempalte.
gen_instance_template_metadata() {
  local EXISTING_METADATA; EXISTING_METADATA="${1}";
  jq -n --arg mesh_agent_bucket "${MESH_AGENT_BUCKET}" \
  --arg root_cert "${ROOT_CERT}"\
  --arg startup_script "${STARTUP_SCRIPT}" \
  --arg declaration "${GCE_SOFTWARE_DECLARATION}"\
  --arg gce_service_proxy "${GCE_SERVICE_PROXY}" '[{
"value": "true",
"key": "enable-guest-attributes"
},
{
  "value": "true",
  "key": "enable-osconfig"
},
{
  "value": $mesh_agent_bucket,
  "key": "service-proxy-agent-bucket"
},
{
  "value": $declaration,
  "key": "gce-software-declaration"
},
{
  "value": $root_cert,
  "key": "rootcert"
},
{
  "value": $gce_service_proxy,
  "key": "gce-service-proxy"
},
{
  "value": $startup_script,
  "key": "startup-script"
}]' | jq ". + [${EXISTING_METADATA}]"
}

# Generate the labels on GCE VMs.
gen_gce_instance_labels() {
  jq -n \
  --arg canonical_service "${CANONICAL_SERVICE}" \
  --arg project_id "${PROJECT_ID}" \
  --arg project_number "${PROJECT_NUMBER}" '{
"gce-service-proxy": "asm-istiod",
"asm_service_name": $canonical_service,
"asm_service_namespace": $project_id,
"mesh_id": ("proj-"+$project_number)
}'
}

# Generate a default instance template.
gen_default_instance_template() {
  jq -n \
  --arg project_id "${PROJECT_ID}" \
  --arg project_number "${PROJECT_NUMBER}" \
  --arg instance_template "${NEW_INSTANCE_TEMPLATE}" '{
  "name": $instance_template,
  "properties": {
    "machineType": "n1-standard-1",
    "displayDevice": {
      "enableDisplay": false
    },
    "metadata": {
      "kind": "compute#metadata"
    },
    "disks": [
      {
        "kind": "compute#attachedDisk",
        "type": "PERSISTENT",
        "boot": true,
        "mode": "READ_WRITE",
        "autoDelete": true,
        "deviceName": $instance_template,
        "initializeParams": {
          "sourceImage": "projects/debian-cloud/global/images/family/debian-10",
          "diskType": "pd-standard",
          "diskSizeGb": "10"
        }
      }
    ],
    "canIpForward": false,
    "networkInterfaces": [
      {
        "kind": "compute#networkInterface",
        "network": ("projects/"+$project_id+"/global/networks/default"),
        "accessConfigs": [
          {
            "kind": "compute#accessConfig",
            "name": "External NAT",
            "type": "ONE_TO_ONE_NAT",
            "networkTier": "PREMIUM"
          }
        ]
      }
    ],
    "scheduling": {
      "preemptible": false,
      "onHostMaintenance": "MIGRATE",
      "automaticRestart": true
    },
    "reservationAffinity": {
      "consumeReservationType": "ANY_RESERVATION"
    },
    "serviceAccounts": [
      {
        "email": ($project_number+"-compute@developer.gserviceaccount.com"),
        "scopes": [
          "https://www.googleapis.com/auth/cloud-platform"
        ]
      }
    ],
    "labels": {}
  }
}'
}

create_gce_instance_template() {
  info "Preparing and creating the GCE instance template..."

  local GCE_SERVICE_PROXY
  GCE_SERVICE_PROXY="$(gen_gce_service_proxy)"

  local GCE_SOFTWARE_DECLARATION
  GCE_SOFTWARE_DECLARATION="$(gce_software_declaration)"

  local VM_LABELS; VM_LABELS="$(gen_gce_instance_labels)"

  # Create the instance template creation request.
  local INSTANCE_TEMPLATE_REQ; INSTANCE_TEMPLATE_REQ="";
  local EXISTING_STARTUP_SCRIPT; EXISTING_STARTUP_SCRIPT="";
  local EXISTING_METADATA; EXISTING_METADATA="";
  if [[ -z "${SOURCE_INSTANCE_TEMPLATE}" ]]; then
    INSTANCE_TEMPLATE_REQ="$(gen_default_instance_template)"
  else
    # Retrieve the existing instance template definition and replace its name
    # with the new instance template name.
    INSTANCE_TEMPLATE_REQ="$(retry 2 run gcloud compute instance-templates \
      describe "${SOURCE_INSTANCE_TEMPLATE}" \
      --format=json \
      --project="${PROJECT_ID}" \
      | jq --arg name "${NEW_INSTANCE_TEMPLATE}" \
      '.name=$name | .properties.disks[].deviceName=$name' || true)"

    # Extract the existing startup script, if there is one.
    EXISTING_STARTUP_SCRIPT="$(echo "${INSTANCE_TEMPLATE_REQ}" \
      | jq '.properties.metadata.items | .[]? | select(.key=="startup-script") | .value' \
      | sed -e 's/^"//' -e 's/"$//')"

    # Extract the existing metadata except the startup-script.
    EXISTING_METADATA="$(echo "${INSTANCE_TEMPLATE_REQ}" \
      | jq '.properties.metadata.items | .[]? | select(.key!="startup-script")')"
  fi

  local STARTUP_SCRIPT; STARTUP_SCRIPT="$(gen_startup_script "${EXISTING_STARTUP_SCRIPT}")";

  local METADATA; METADATA="$(gen_instance_template_metadata "${EXISTING_METADATA}")";

  # Inject the GCE VM labels into the instance template.
  INSTANCE_TEMPLATE_REQ=$(jq --argjson metadata "${METADATA}" \
    --argjson labels "${VM_LABELS}" \
   '.properties.metadata.items = $metadata | .properties.labels += $labels' \
   <<< "${INSTANCE_TEMPLATE_REQ}")

  # Create the instance template and get the creation operation.
  local TOKEN; TOKEN="$(retry 2 gcloud \
    --project="${PROJECT_ID}" auth print-access-token)"

  local RESPONSE
  RESPONSE="$(run curl -s -H "Content-Type: application/json" \
    -XPOST "https://www.googleapis.com/compute/v1/projects/${PROJECT_ID}/global/instanceTemplates"\
    -d "${INSTANCE_TEMPLATE_REQ}" \
    -H @- <<EOF
Authorization: Bearer ${TOKEN}
EOF
)"

  local OP_NAME
  OP_NAME="$(echo "${RESPONSE}" | jq '.name' | tr -d '"')"
  if [[ "${OP_NAME}" == "null" ]]; then
    local ERROR;
    ERROR="$(jq '.error.message' <<< "${RESPONSE}")"
    fatal "GCE instance template creation failed: ${ERROR}"
  else
    # Wait and check if the creation is done.
    local RETVAL
    { watch_for_result 5 "^DONE$" gcloud compute operations describe "${OP_NAME}" \
      --format="value(status)" --project="${PROJECT_ID}" >/dev/null; RETVAL="$?"; } || true
    if [[ "${RETVAL}" -ne 0 ]]; then
      { read -r -d '' MSG; fatal "${MSG}"; } <<EOF
Unable to create GCE instance template ${NEW_INSTANCE_TEMPLATE}.
Please check the details of the error:
  gcloud compute operations describe "${OP_NAME}" --project="${PROJECT_ID}"
EOF
    fi
  fi

}

success_message_create_gce_instance_template() {
  info "
*****************************
The GCE Instance Template for ASM VM is now created.

To create a single instance from the instance template, run:
  gcloud compute instances create <INSTANCE_NAME>\
  --source-instance-template ${NEW_INSTANCE_TEMPLATE} --project=${PROJECT_ID}

To create a managed instance group from the instance template, run:
  gcloud compute instance-groups managed create <INSTANCE_GROUP_NAME>\
  --base-instance-name <BASE_NAME>\
  --size <SIZE>\
  --template ${NEW_INSTANCE_TEMPLATE}\
  --zone <ZONE>
*****************************
"
}

main() {
  parse_args "${@}"
  validate_args

  if [[ -n "${SERVICE_ACCOUNT}" ]]; then
    auth_service_account
  fi

  validate_dependencies
  info "Successfully validated all prerequistes from this shell."
  if [[ "${ONLY_VALIDATE}" -ne 0 ]]; then
    return 0
  fi

  extract_canonical_service_label
  extract_canonical_service_revision
  if [[ "${CREATE_GCE_INSTANCE_TEMPLATE}" -eq 1 ]]; then
    retrieve_cluster_root_cert
    retrieve_ingressgateway
    create_gce_instance_template
    success_message_create_gce_instance_template
  fi

  return 0
}

main "${@}"
