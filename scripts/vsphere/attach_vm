#!/bin/bash

if [[ ! -z "${LOG_LEVEL}" ]]; then
  set -ex
else
  set -CeE
fi
set -o pipefail
set +o noclobber
set +o verbose

source vsphere/util.sh

main() {
  echo "============================================="
  init
  read_args "${@}"
  write_config_context_vm

  echo "[Step 1] Register VM at namespace: ${VM_NAMESPACE}"
  create_workloadgroup

  echo "[Step 2] Copy configuration files to VM: ${VM_APP}@${VM_IP}"
  configure_vm_transfer_file

  echo "[Step 3] Install ASM agent on VM"
  runagent

}

create_workloadgroup() {
  cd ${OUTPUT_DIR}/vm-${VM_APP}

  # Register VM and create a service for the VM
  cat <<EOF >workloadgroup.yaml
apiVersion: networking.istio.io/v1alpha3
kind: WorkloadGroup
metadata:
  name: "${VM_APP}"
  namespace: "${VM_NAMESPACE}"
spec:
  metadata:
    labels:
      app: "${VM_APP}"
  template:
    serviceAccount: "${SERVICE_ACCOUNT}"
    network: "${VM_NETWORK}"
EOF

  # add more labels for vm workloadgroup
  if [[ -n "${LABELS}" ]]; then
    if [[ ${LABELS:0:1} == "\"" ]] ; then LABELS=${LABELS:1:-1};  fi
    tmpLabels=(${LABELS//;/ })
    echo ${tmpLabels[@]}
    for tmplabel in "${tmpLabels[@]}"; do
      curLabels=(${tmplabel//:/ })

      tmplabel0=${curLabels[0]}
      tmplabel0+=":\ \""
      tmplabel0+=${curLabels[1]}
      tmplabel0+="\""

      sed -i -e "10 i \ \ \ \ \ \ $tmplabel0" workloadgroup.yaml
    done
  fi

  kubectl --namespace "${VM_NAMESPACE}" apply -f workloadgroup.yaml
}

configure_vm_transfer_file() {
  # Create files to transfer to VM
  cd ${WORK_DIR}
  if [[ -z "${REVISION}" ]]; then
    istioctl x workload entry configure -f ${OUTPUT_DIR}/vm-${VM_APP}/workloadgroup.yaml -o ${OUTPUT_DIR}/vm-${VM_APP} --clusterID ${CLUSTER} --autoregister
  else
    istioctl x workload entry configure --revision ${REVISION} -f ${OUTPUT_DIR}/vm-${VM_APP}/workloadgroup.yaml -o ${OUTPUT_DIR}/vm-${VM_APP} --clusterID ${CLUSTER} --autoregister
  fi

  cd ${OUTPUT_DIR}/vm-${VM_APP}

  multinicdetection

  ssh -i "${KEY_FILE}" -o StrictHostKeyChecking=no root@${VM_IP} mkdir "${VM_DIR}" || true
  scp -i "${KEY_FILE}" -o StrictHostKeyChecking=no sidecar.env cluster.env hosts istio-token mesh.yaml root-cert.pem root@${VM_IP}:"${VM_DIR}"

  cd ${WORK_DIR}
  if [[ ! -e "vsphere/runagent.sh" ]]; then
    fatal "file vsphere/runagent.sh does not exists in working dir ${WORK_DIR}"
  fi

  scp -i "${KEY_FILE}" -o StrictHostKeyChecking=no vsphere/runagent.sh root@${VM_IP}:"${VM_DIR}"

  if [[ "${IMAGE}" == "rpm" ]]; then
    if [[ ! -e "istio-sidecar.rpm" ]]; then
      fatal "file istio-sidecar.rpm does not exists in working dir ${WORK_DIR}"
    fi
    scp -i "${KEY_FILE}" -o StrictHostKeyChecking=no istio-sidecar.rpm root@${VM_IP}:"${VM_DIR}"
  else
    # deb VM
    if [[ ! -e "istio-sidecar.deb" ]]; then
      fatal "file istio-sidecar.deb does not exists in working dir ${WORK_DIR}"
    fi
    scp -i "${KEY_FILE}" -o StrictHostKeyChecking=no istio-sidecar.deb root@${VM_IP}:"${VM_DIR}"
  fi
}

runagent() {
  # SSH to VM and execute runagent.sh on VM
  runagentcmd="chmod +x ${VM_DIR}/runagent.sh; ${VM_DIR}/runagent.sh ${VM_DIR} ${IMAGE}"
  until ssh -i "${KEY_FILE}" -o StrictHostKeyChecking=no root@${VM_IP} ${runagentcmd}; do
    sleep 1
  done

  # verify workload entry generation
  ENTRY="${VM_APP}-${MANAGED_ADDR}-${VM_NETWORK}"
  sleep 3
  until [[ ! -z $(kubectl get workloadentry ${ENTRY} -n ${VM_NAMESPACE} -o name) ]]; do
    sleep 1
    kubectl get workloadentry ${ENTRY} -n ${VM_NAMESPACE}
  done

  ENTRY_RES="$(kubectl get workloadentry ${ENTRY} -n ${VM_NAMESPACE} -o name)"

  if [[ ${ENTRY_RES} == *"Error"* ]]; then
    fatal "Failed to generate workloadentry for attached VM with context ${ENTRY_RES}. Please check trouble shooting section in user guide."
  fi

  echo "============================================="
  echo -e "\xE2\x9C\x94 Under the context of cluster:${CLUSTER} clusterNetwork:${CLUSTER_NETWORK} vmNetwork:${VM_NETWORK}"
  echo -e "\xE2\x9C\x94 successfully add vm:${VM_APP} addr:${VM_IP} managed_address:${MANAGED_ADDR} nic:${MANAGED_NIC} sa:${SERVICE_ACCOUNT} ns:${VM_NAMESPACE}"
}

write_config_context_vm() {
  # select different context from current context
  if [[ -n "${SELECT_CONTEXT}" ]]; then
    export CONTEXT="${SELECT_CONTEXT}"
  elif [[ ! -e "./.currContext" || ! -s "./.currContext" ]]; then
    # attach vm directly without set context
    export CONTEXT="attachConfig"
  else
    currContext=$(cat "./.currContext")
    export CONTEXT=${currContext:10}
  fi

  source "./.${CONTEXT}"
  source "./.attachConfig"
  fill_unspecified_context

  alias istioctl="istioctl --kubeconfig ${KUBECONFIG}"

  if [[ -e ${OUTPUT_DIR}/vm-${VM_APP} ]]; then
    rm -rf ${OUTPUT_DIR}/vm-${VM_APP}
  fi

  if [[ ! -e ${OUTPUT_DIR} ]]; then
    mkdir ${OUTPUT_DIR}
  fi

  mkdir -p ${OUTPUT_DIR}/vm-${VM_APP}
  CONTEXT_FILE=${OUTPUT_DIR}/vm-${VM_APP}/".context"

  write_config_context

  echo "export VM_APP=${VM_APP}" >>${CONTEXT_FILE}
  echo "export VM_IP=${VM_IP}" >>${CONTEXT_FILE}

  rm ".attachConfig"
  cat ${OUTPUT_DIR}/vm-${VM_APP}/".context"
}

# multi nic support
multinicdetection() {
  # cache all VM ip table info for later use
  IP_INFO=$(ssh -i "${KEY_FILE}" -o StrictHostKeyChecking=no root@${VM_IP} ip -j a )

  NICCOUNTSTRING=$(echo "${IP_INFO}" | jq -jr '.[].ifname| type')
  NICSTRING=$(echo "${IP_INFO}" | jq -jr '.[]|" ",.ifname')

  # Case 1: VM has only one nic. fill in MANAGED_ADDR and MANAGED_NIC if unspecified.
  # if a VM has 2 nic like {lo ens192}, NICCOUNTSTRING="stringstring". The length is 12. Users don't need to specify --managed-nic or --managed-address
  if [[ ${#NICCOUNTSTRING} == 12 ]]; then
    VMNICNAME=$(echo "${IP_INFO}"| jq -r '.[] | select(.ifname=="lo" | not) | .ifname')

    if [[ -z "${MANAGED_NIC}" ]]; then
      MANAGED_NIC="${VMNICNAME}"
    fi
    if [[ -z "${MANAGED_ADDR}" ]]; then
      MANAGED_ADDR="${VM_IP}"
    fi

    if [[ "${MANAGED_ADDR}" != "${VM_IP}" || "${MANAGED_NIC}" != "${VMNICNAME}" ]]; then
      # User might input a wrong addr or nic which doesn't match MANAGED_ADDR or MANAGED_NIC filled in above.
      # User might input a unmatched addr and nic
      fatal "Cannot find the input nic name or ip."
    fi
  fi

  # Case 2: VM has multiple nic.
  # if a VM has more than 2 nic like {lo ens192 ens224}, NICCOUNTSTRING="stringstringstring". User need to specify at least a --managed-nic or --managed-address
  if [[ ${#NICCOUNTSTRING} > 12 ]]; then
    if [[ -z "${MANAGED_ADDR}" && -z "${MANAGED_NIC}" ]]; then
      fatal "Detect undefined behavior. The VM is has more than one Nic. User need to specify managed nic name with one nic name out of ${NICSTRING}. Please specify with --managed-nic and --managed-address in the attaching process"
    fi

    if [[ -z "${MANAGED_ADDR}" ]]; then
      # unspecified MANAGED_ADDR
      MANAGED_ADDR=$(echo "${IP_INFO}"| jq -r ".[] | select(.ifname == \"${MANAGED_NIC}\") | .addr_info[] | select(.family == \"inet\" and .scope == \"global\") | .local")
      # TODO: xulingqing(linggg) deal with case when a nic corresponding to multiple IPs
      if [[ -z "${MANAGED_ADDR}" ]]; then
        fatal "Cannot find nic with name ${MANAGED_NIC} on VM."
      fi
    elif [[ -z "${MANAGED_NIC}" ]]; then
      # unspecified MANAGED_NIC
      MANAGED_NIC=$(echo "${IP_INFO}"| jq -r ".[] | select(.addr_info[].local == \"${MANAGED_ADDR}\") | .ifname")
      if [[ -z "${MANAGED_NIC}" ]]; then
        fatal "Cannot find nic with ipv4 addr ${MANAGED_ADDR} on VM."
      fi
    fi

    # User might input a unmatched addr and nic
    INPUTNICIP=$(echo "${IP_INFO}"| jq -r ".[] | select(.ifname == \"${MANAGED_NIC}\") | .addr_info[] | select(.family == \"inet\" and .scope == \"global\") | .local")

    if [[ "${INPUTNICIP}" != "${MANAGED_ADDR}" ]]; then
      IPNICNAME=$(echo "${IP_INFO}"| jq -r ".[] | select(.addr_info[].local == \"${MANAGED_ADDR}\") | .ifname")
      fatal "User input for nic name and nic address is not matched.\n Input MANAGED_NIC: ${MANAGED_NIC} corresponding to IP address ${INPUTNICIP}. Input MANAGED_ADDR ${MANAGED_ADDR} corresponding to NIC name ${IPNICNAME}."
    fi
  fi

  multinicsetup
}

multinicsetup() {
  echo "Starting Multi-nic setup"

  # adding 2 lines to cluster.env
  # ISTIO_SVC_IP=${managed_address}
  # ISTIO_EXCLUDE_INTERFACES=${NICs' name exclude the managed-nic}

  echo "ISTIO_SVC_IP=${MANAGED_ADDR}" >> cluster.env
  echo "export MANAGED_ADDR=${MANAGED_ADDR}" >>${CONTEXT_FILE}

  # all NICs name exclude the $(managed-nic)  and "lo". Seperating with ","
  EXCLUDE_NIC=$(echo "${IP_INFO}"| jq -jr ".[] | select(.ifname!=\"lo\" and .ifname!=\"${MANAGED_NIC}\") | .ifname,\",\"")

  # remove last comma and write to cluster.env
  echo "ISTIO_EXCLUDE_INTERFACES='${EXCLUDE_NIC%?}'" >> cluster.env

  # record nic selection in .context file
  echo "export MANAGED_NIC=${MANAGED_NIC}" >>${CONTEXT_FILE}
  echo "export MANAGED_ADDR=${MANAGED_ADDR}" >>${CONTEXT_FILE}
  echo "export ISTIO_EXCLUDE_INTERFACES='${EXCLUDE_NIC%?}'" >>${CONTEXT_FILE}
}

main "${@}"
